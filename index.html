<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <style type="text/css">
        body {
          background-color: #f5f5f5;
          font-family: charter;
        }
        .container {
            background-color: #fff;
            zoom: 1;
            margin-left: auto;
            margin-right: auto;
            vertical-align: middle;
            text-align: left;
            width: 100%;
            max-width: 800px;
            padding: 20px;
            margin: 20px auto;
        }
        .content {
            margin-bottom: -10px;
            display: inline-block;
            display*: inline;
            width: 100%;
        }
        a {
          color: #03c;
          text-decoration: none;
          transition: 0.3s all cubic-bezier(0.42, 0, 0.57, 1.96);
        }
    
        a:focus,
        a:hover{
          color: rgb(252, 76, 122);
          border-color: rgb(252, 76, 122);
        }
        .publogo { width: 230px; max-height: 190px; margin-right : 15px; float : left; border : 0;}
        .publication { clear : left; padding-bottom : 0px; }
        .publication p { height : 100px; padding-top : 5px;}
        .publication strong a { font-size: 17px; color : #0000A0; }
        .publication .links { position : relative; top : 15px }
        .publication .links a { margin-right : 20px; }
    </style>
    <title>Jihan Yang's Homepage</title>
    <!-- <link rel="icon" href="../content/images/icon.png"> -->
  </head>
  <body>
    <div class="container">
        <table width="100%" align="center" border="0">
<tr>
    <td width="60%" valign="middle">
        <h1 style="margin-top:18px;margin-bottom:36px; color:rgb(59, 103, 236)">Jihan Yang</h1>
        <p style="font-size:18px; color:rgb(0, 0, 0)">
	        <b>Ph.D. student</b> <br />
            Department of Electrical and Electronic Engineering  <br />
	        The University of Hong Kong
            <br /><br />
            Email: jihanyang13 [at] gmail [dot] com
        </p>
        <p>
            <a href="https://scholar.google.com/citations?user=zWfNZnIAAAAJ&hl=en">[Google Scholar]</a> &nbsp;
            <a href="https://github.com/jihanyang">[GitHub]</a> &nbsp;
            <a href="https://twitter.com/jihanyang13">[Twitter]</a> &nbsp;
        </p>
    </td>
    <td width="40%" align="center">
        <img src="content/images/myfigure.jpg" width="70%" />
    </td>
</tr>
</table>

<h2 id="about-me" style="color:rgb(59, 103, 236)">Biography</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<p>I am currently a PhD student (2020-) at EEE, The University of Hong Kong, advised by <a href="https://xjqi.github.io/">Dr. Xiaojuan Qi</a>. Before that
I obtained my Bachelor's degree from Sun Yat-sen University, supervised by <a href="http://www.linliang.net/">Prof. Liang Lin</a> and <a href="http://guanbinli.com/">Prof. Guanbin Li</a>. I am also working closely with Ruijia Xu, <a href="https://shishaoshuai.com/">Dr. Shaoshuai Shi</a>, <a href="https://dingry.github.io/">Runyu Ding</a> and <a href="https://wang-zhe.me/">Dr. Zhe Wang</a>.
</p>

<p>My research interests focus on machine learning, vision and embodied ai.</p>

<p style="color:rgb(247, 13, 29)"><strong><i>(I am looking for researcher or postdoc positions in 2024 fall! Reach out to me if youâ€™re intersted!)</i></strong></p>

<h2 id="news" style="color:rgb(59, 103, 236)">News</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<ul>
  <li>[2023/02] One paper accepted by CVPR 2023.</li>
  <li>[2022/09] One paper accepted by T-PAMI.</li>
  <li>[2022/09] One paper accepted by NeurIPS 2022.</li>
  <li>[2022/07] One paper accepted by ECCV 2022.</li>
</ul>

<script type="text/javascript">
    function hideshow(which){
    if (!document.getElementById)
        return
    if (which.style.display=="block")
        which.style.display="none"
    else
        which.style.display="block"
    }
</script>


<h2 id="codebase" style="color:rgb(59, 103, 236)">Codebase</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<table class="">
<tr>
    <td width="30%" valign="top">
        <img src="content/images/pcdet_min.png" width="96%" height="100" />
    </td>
    <td width="70%" valign="top">
        <div style="margin-top:0px;margin-bottom:0px;">
        <a href="https://github.com/open-mmlab/OpenPCDet" style="">
            OpenPCDet: An Open-source Toolbox for 3D Object Detection from Point Cloud
        </a>
        <br>
        <br />
        <font color="#000000">OpenPCDet Development Team </font>
        <br />
        <font style="font-size:15px;"><em>
      <!--       arXiv:1912.13192, Technical Report, 2019
            </em>  -->
            June 2020
            </em> 
        </font>
        <br>
        <br />
        <a href="https://github.com/open-mmlab/OpenPCDet" style="">[Code]</a> &nbsp;   
            <a href="javascript:hideshow(document.getElementById('OpenPCDet'))"> [Bibtex] </a> &nbsp; 
            <a href="https://github.com/open-mmlab/OpenPCDet"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/open-mmlab/OpenPCDet?style=social" /> </a> 
        <br />
        </div>
    </td>
</tr>
</table>
<!-- <pre><p id="OpenPCDet" style="font:18px; display:none">
@inproceedings{shi2020pcdet,
  title={OpenPCDet: An Open-source Toolbox for 3D Object Detection from Point Cloud},
  author={Shi, Shaoshuai and Guo, Chaoxu and Li, Hongsheng},
  Journal ={https://github.com/open-mmlab/OpenPCDet},
  year={2020}
}
</p></pre> -->
<pre><p id="OpenPCDet" style="font:18px; display:none">
@misc{openpcdet2020,
    title={OpenPCDet: An Open-source Toolbox for 3D Object Detection from Point Clouds},
    author={OpenPCDet Development Team},
    howpublished = {\url{https://github.com/open-mmlab/OpenPCDet}},
    year={2020}
}
</p></pre>



<h2 id="publications" style="color:rgb(59, 103, 236)">Selected Publications <a href="https://scholar.google.com/citations?user=zWfNZnIAAAAJ&hl=en">[Google Scholar]</a></h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<p>*: Equal Contribution</p>

<!-- **Selected Preprints:** -->

<!-- <ul>
  
</ul> -->

<!-- **2023:** -->
<div class="publication">
  <img src="content/images/RegionPLC.png" class="publogo">
  <p> 
      <strong>
          <a href="https://arxiv.org/pdf/2304.00962.pdf">RegionPLC: Regional Point-Language Contrastive Learning for Open-World 3D Scene Understanding
          </a>
      </strong>
      <br>
      <b>Jihan Yang*</b>, Runyu Ding*, Weipeng Deng, Zhe Wang, Xiaojuan Qi.
      <br>
      <em>arXiv Preprint</em>
      <br>
      <span class="links">
          <a href="https://arxiv.org/pdf/2304.00962.pdf">[PDF]</a>
          <a href="https://jihanyang.github.io/projects/RegionPLC">[Project Page]</a>
      </span>
  </p>
</div>
<br>
<br>
<br>


<!-- **2022:** -->
<div class="publication">
  <img src="content/images/pla_teaser.gif" class="publogo">
  <p> 
      <strong>
          <a href="https://arxiv.org/pdf/2211.16312.pdf">PLA: Language-driven Open-Vocabulary 3D Scene Understanding</a>
      </strong>
      <br>
      Runyu Ding*, <b>Jihan Yang*</b>, Chuhui Xue, Wenqing Zhang, Song Bai, Xiaojuan Qi.
      <br>
      <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023</em>
      <br>
      <span class="links">
          <a href="https://arxiv.org/pdf/2211.16312.pdf">[PDF]</a>
          <a href="https://dingry.github.io/projects/PLA">[Project Page]</a>
          <a href="https://github.com/CVMI-Lab/PLA">[Code]</a><a href="https://github.com/CVMI-Lab/PLA"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/PLA?style=social" /> </a>
      </span>
  </p>
</div>
<br>
<br>


<div class="publication">
  <img src="content/images/sparsekd_teaser.png" class="publogo" style="width:210px ;padding-right:10px; padding-left:10px">
  <p> 
      <strong>
        <a href="https://arxiv.org/abs/2205.15156">Towards Efficient 3D Object Detection with Knowledge Distillation</a>
      </strong>
      <br>
      <b>Jihan Yang</b>, Shaoshuai Shi, Runyu Ding, Zhe Wang, Xiaojuan Qi
      <br>
      <em>Advances in Neural Information Processing Systems (NeurIPS) 2022.</em>
      <br>
      <span class="links">
          <a href="https://arxiv.org/abs/2205.15156">[PDF]</a>
          <a href="https://github.com/CVMI-Lab/SparseKD">[Code]</a> <a href="https://github.com/CVMI-Lab/SparseKD"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/SparseKD?style=social" /> </a>
      </span>
  </p>
</div>
<br>
<br>
<br>
<br>


<div class="publication">
  <img src="content/images/st3d++_teaser.png" class="publogo" style="padding-bottom:40px;">
  <p> 
      <strong>
        <a href="https://arxiv.org/abs/2108.06682">ST3D++: Self-training for Unsupervised Domain Adaptation on 3D Object Detection</a>
      </strong>
      <br>
      <b>Jihan Yang</b>, Shaoshuai Shi, Zhe Wang, Hongsheng Li, Xiaojuan Qi
      <br>
      <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI) 2022.</em>
      <br>
      <span class="links">
          <a href="https://arxiv.org/abs/2108.06682">[PDF]</a>
          <a href="https://github.com/CVMI-Lab/ST3D">[Code]</a> <a href="https://github.com/CVMI-Lab/ST3D"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/ST3D?style=social" /> </a>
      </span>
  </p>
</div>
<br>
<br>

<div class="publication">
  <img src="content/images/doda_teaser.png" class="publogo" style="padding-bottom:20px;">
  <p> 
      <strong>
        <a href="https://arxiv.org/abs/2204.01599">DODA: Data-oriented Sim-to-Real Domain Adaptation for 3D Indoor Semantic Segmentation</a>
      </strong>
      <br>
      Runyu Ding*, <b>Jihan Yang*</b>, Xiaojuan Qi
      <br>
      <em>European Conference on Computer Vision (ECCV), 2022.</em>
      <br>
      <span class="links">
          <a href="https://arxiv.org/abs/2204.01599">[PDF]</a>
          <a href="https://github.com/CVMI-Lab/DODA">[Code]</a> <a href="https://github.com/CVMI-Lab/DODA"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/DODA?style=social" /> </a>
      </span>
  </p>
</div>
<br>
<br>


<div class="publication">
  <img src="content/images/dars_teaser.png" class="publogo" style="padding-bottom:20px;">
  <p> 
      <strong>
        <a href="https://arxiv.org/abs/2107.11279">Re-distributing Biased Pseudo Labels for Semi-supervised Semantic Segmentation: A Baseline Investigation</a>
      </strong>
      <br>
      Ruifei He*, <b>Jihan Yang*</b>, Xiaojuan Qi
      <br>
      <em>IEEE International Conference on Computer Vision (ICCV), 2021.</em>
      <span style="color:red;"><strong>[Oral]</strong></span>
      <br>
      <span class="links">
          <a href="https://arxiv.org/abs/2107.11279">[PDF]</a>
          <a href="https://github.com/CVMI-Lab/DARS">[Code]</a> <a href="https://github.com/CVMI-Lab/DARS"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/DARS?style=social" /> </a>
      </span>
  </p>
</div>
<br>
<br>


<div class="publication">
  <img src="content/images/st3d_teaser.png" class="publogo" style="padding-bottom:20px;">
  <p> 
      <strong>
        <a href="https://arxiv.org/abs/2103.05346">ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection</a>
      </strong>
      <br>
      <b>Jihan Yang*</b>, Shaoshuai Shi*, Zhe Wang, Hongsheng Li, Xiaojuan Qi
      <br>
      <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</em>
      <br>
      <span class="links">
          <a href="https://arxiv.org/abs/2103.05346">[PDF]</a>
          <a href="https://github.com/CVMI-Lab/ST3D">[Code]</a> <a href="https://github.com/CVMI-Lab/ST3D"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/ST3D?style=social" /> </a>
      </span>
  </p>
</div>
<br>
<br>



<div class="publication">
  <img src="content/images/apoda_teaser.png" class="publogo" style="padding-bottom:20px;">
  <p> 
      <strong>
        <a href="https://arxiv.org/abs/1912.08954">An adversarial perturbation oriented domain adaptation approach for semantic segmentation</a>
      </strong>
      <br>
      <b>Jihan Yang</b>, Ruijia Xu, Ruiyu Li, Xiaojuan Qi, Xiaoyong Shen, Guanbin Li, Liang Lin
      <br>
      <em>AAAI, 2020.</em>
      <br>
      <span class="links">
          <a href="https://arxiv.org/abs/1912.08954">[PDF]</a>
      </span>
  </p>
</div>
<br>
<br>


<div class="publication">
  <img src="content/images/afn_teaser.png" class="publogo" style="padding-bottom:20px;">
  <p> 
      <strong>
        <a href="https://arxiv.org/abs/1811.07456">Larger Norm More Transferable: An Adaptive Feature Norm Approach for Unsupervised Domain Adaptation</a>
      </strong>
      <br>
      Ruijia Xu, Guanbin Li, <b>Jihan Yang</b>, Liang Lin
      <br>
      <em>IEEE International Conference on Computer Vision (ICCV), 2019.</em><span style="color:red;"><strong>[Oral]</strong></span>
      <br>
      <span class="links">
          <a href="https://arxiv.org/abs/1811.07456">[PDF]</a>
          <a href="https://github.com/jihanyang/AFN">[Code]</a> <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/jihanyang/AFN?style=social" />
      </span>
      <br>
      <br>
      <span style="color: #FF0000">Best Paper Award Nomination (one of the seven among 1,075 accepted papers) refer to <a href="https://iccv2019.thecvf.com/program/main_conference" style="">here.</a></span>
  </p>
</div>
<br>
<br>
<br>
<br>


<!-- <ul>
<li><a href="https://arxiv.org/pdf/2211.16312.pdf">Language-driven Open-Vocabulary 3D Scene Understanding</a><br />
    Runyu Ding*, <b>Jihan Yang*</b>, Chuhui Xue, Wenqing Zhang, Song Bai, Xiaojuan Qi<br />
    <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</em>
<a href="https://github.com/CVMI-Lab/PLA">[Code]</a> Â <a href="https://github.com/CVMI-Lab/PLA"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/PLA?style=social" /> </a></p>
</li>
 <li><a href="https://arxiv.org/abs/2205.15156">Towards Efficient 3D Object Detection with Knowledge Distillation</a><br />
    <b>Jihan Yang</b>, Shaoshuai Shi, Runyu Ding, Zhe Wang, Xiaojuan Qi<br />
    <em>Advances in Neural Information Processing Systems (NeurIPS) 2022.</em>
<a href="https://github.com/CVMI-Lab/SparseKD">[Code]</a> Â <a href="https://github.com/CVMI-Lab/SparseKD"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/SparseKD?style=social" /> </a></p>
</li>
  <li>
    <p><a href="https://arxiv.org/abs/2108.06682">ST3D++: Self-training for Unsupervised Domain Adaptation on 3D Object Detection</a><br />
        <b>Jihan Yang</b>, Shaoshuai Shi, Zhe Wang, Hongsheng Li, Xiaojuan Qi<br />
<em>IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI) 2022.</em>
<a href="https://github.com/CVMI-Lab/ST3D">[Code]</a> Â <a href="https://github.com/CVMI-Lab/ST3D"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/ST3D?style=social" /> </a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2204.01599">DODA: Data-oriented Sim-to-Real Domain Adaptation for 3D Indoor Semantic Segmentation</a><br />
Runyu Ding*, <b>Jihan Yang*</b>, Xiaojuan Qi<br />
<em>European Conference on Computer Vision (ECCV), 2022.</em>
<a href="https://github.com/CVMI-Lab/DODA">[Code]</a><a href="https://github.com/CVMI-Lab/DODA"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/DODA?style=social" /> </a>
</p>
  </li>
</ul> -->

<!-- **2021:** -->
<!-- <ul>
  <li>
    <p><a href="https://arxiv.org/abs/2107.11279">Re-distributing Biased Pseudo Labels for Semi-supervised Semantic Segmentation: A Baseline Investigation</a><br />
        Ruifei He*, <b>Jihan Yang*</b>, Xiaojuan Qi<br />
<em>IEEE International Conference on Computer Vision (ICCV), 2021.</em> 
<span style="color:red;"><strong>[Oral]</strong></span> Â 
<a href="https://github.com/CVMI-Lab/DARS">[Code]</a> Â <a href="https://github.com/CVMI-Lab/DARS"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/DARS?style=social" /> </a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2103.05346">ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection</a><br />
        <b>Jihan Yang*</b>, Shaoshuai Shi*, Zhe Wang, Hongsheng Li, Xiaojuan Qi<br />
<em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</em> 
Â <a href="https://github.com/CVMI-Lab/ST3D">[Code]</a> Â <a href="https://github.com/CVMI-Lab/ST3D"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CVMI-Lab/ST3D?style=social" /> </a></p>
  </li>
</ul> -->

<!-- **2020** -->
<!-- <ul>
  <li>
    <p><a href="https://arxiv.org/abs/1912.08954">An adversarial perturbation oriented domain adaptation approach for semantic segmentation</a> <br />
<b>Jihan Yang</b>, Ruijia Xu, Ruiyu Li, Xiaojuan Qi, Xiaoyong Shen, Guanbin Li, Liang Lin<br />
<em>AAAI, 2020.</em> </p>
  </li>
</ul> -->

<!-- **Before 2020** -->

<!-- <ul>
  <li>
    <p><a href="https://arxiv.org/abs/1811.07456">Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation</a><br />
 Ruijia Xu, Guanbin Li, <b>Jihan Yang</b>, Liang Lin<br />
<em>IEEE International Conference on Computer Vision (ICCV), 2019.</em> <span style="color:red;"><strong>[Oral]</strong></span>
Â  <a href="https://github.com/jihanyang/AFN" style="">[Code]</a> <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/jihanyang/AFN?style=social" /><br />
<span style="color: #FF0000">Best Paper Award Nomination (one of the seven among 1,075 accepted papers) refer to <a href="https://iccv2019.thecvf.com/program/main_conference" style="">here.</a></span></p>
  </li>
</ul> -->


<h2 id="experience" style="color:rgb(59, 103, 236)">Experience</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<ul>
  <li>
    <p>Student Intern, Apirl 2023 - Present, Courant Institute of Mathematical Sciences at NYU.<br />
Working with <a href="https://www.sainingxie.com/">Prof. Saining Xie</a></p>
  </li>

  <li>
    <p>Research Intern, May 2020 - Oct 2020, Autonomous Driving Group of SenseTime, China.<br />
Working with <a href="https://wang-zhe.me/">Dr. Zhe Wang</a>.</p>
  </li>
</ul>

<ul>
  <li>Research Intern, Feb 2019 - Feb 2020, Tencent Youtu Lab, China.<br />
    Working with <a href="https://www.linkedin.com/in/ruiyu-li-09664b134/?originalSubdomain=cn">Dr. Ruiyu Li</a> and <a href="https://scholar.google.com.hk/citations?user=PeMuphgAAAAJ&hl=en">Dr. Xiaoyong Shen</a>.</li>
</ul>

<ul>
    <li>Research Intern, Jul 2018 - Sep 2019, YITU Technology, China.<br />
      </li>
  </ul>


<!-- * Bachelor, Aug 2013 - July 2017, Computer Science and Technology, Harbin Institute Technology. -->

<h2 id="honors--awards" style="color:rgb(59, 103, 236)">Honors &amp; Awards</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />

<table style="border-spacing:2px" width="100%">
    <tbody>
    <tr>
        <td>2nd place on 3D detection, 3D tracking and domain adaptation three tracks of Waymo Open Challenges</td>
        <td style="text-align: right">2020</td>
    </tr>
    <tr>
        <td>Postgraduate Scholarship, HKU</td>
        <td style="text-align: right">2020 - 2024</td>
    </tr>
    <tr>
        <td>Best Paper Nomination, IEEE International Conference on Computer Vision (0.2%)</td>
        <td style="text-align: right">2019</td>
    </tr>
    <tr>
        <td>Excellent Graduate Award of Sun Yat-sen University (2%)</td>
        <td style="text-align: right">2019</td>
    </tr>
    <tr>
        <td>Excellent Dissertations of Sun Yat-sen University (2%)</td>
        <td style="text-align: right">2019</td>
    </tr>
    <tr>
        <td>First Prize Scholarship of Sun Yat-sen University (4%)</td>
        <td style="text-align: right">2017, 2018</td>
    </tr>
   
</tbody></table>

<!-- ###################### -->

<h2 id="Academic_services" style="color:rgb(59, 103, 236)">Academic Services</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />
Conference Reviewer:
<ul>
  <li>CVPR: 21/22/23/24</li>
  <li>ICCV: 21</li>
  <li>ECCV: 22/24</li>
  <li>NeurIPS: 23</li>
  <li>ICLR: 24</li>
  <li>IROS: 23</li>
  <li>AAAI: 21</li>
</ul> 
Journal Reviewer:
<ul>
  <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</li>
</ul> 


<h2 id="Teaching" style="color:rgb(59, 103, 236)">Teaching</h2>
<hr style="margin-top:-16px;margin-bottom:10px;" />
<table id="Teaching" border="0" width="100%">
	<tbody>
		<tr>
			<td>ELEC3249 Pattern Recognition and Machine Intelligence</td><td></td><td style="text-align: right">2022-2023</td>
		</tr>
		<tr>
			<td>ENGG1310 Electricity and Electronics</td><td></td><td style="text-align: right">2021-2022</td>
		</tr>
		<tr>
			<td>ELEC3249 Pattern Recognition and Machine Intelligence</td><td></td><td style="text-align: right">2020-2021</td>
		</tr>
	</tbody>
</table>


<div width="80%" style="margin:10px auto;height: 150px; pointer-events: none;">
<!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=dna1gh75RFxuLTLMZdN7u5SSyiCEmnOtvSjR75TKtTQ&cl=ffffff&w=a"></script> -->
<!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=b8b8b8&w=300&t=n&d=dna1gh75RFxuLTLMZdN7u5SSyiCEmnOtvSjR75TKtTQ&co=ffffff&cmo=fc1a0b&cmn=21c983&ct=827d7d"></script> -->
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=bsE8tO7zuYstQlZ4LK-y0ELcK4Uxw6_BtV4Opk5d6GY&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>
<!-- <a href="https://clustrmaps.com/site/1apwn" title="Visit tracker"><img src="//clustrmaps.com/map_v2.png?cl=59bdf5&w=300&t=tt&d=dna1gh75RFxuLTLMZdN7u5SSyiCEmnOtvSjR75TKtTQ&co=ffffff&ct=b8b3b3" /></a> -->
</div>
<p><br /></p>
<hr style="margin-top:80px;margin-bottom:10px;" />

    </div>
  </body>
</html>
